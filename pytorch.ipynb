{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61e563f2-9e37-4916-9434-45822e8c416f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import matplotlib\n",
    "import os\n",
    "import pdb\n",
    "import time\n",
    "from typing import Any, Callable, Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0036899d-3e33-4680-849c-9b49455dc4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 1001, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "DATA_PATH = \"data.npz\"\n",
    "\n",
    "with open(DATA_PATH, \"rb\") as f:\n",
    "    data = np.load(f)\n",
    "    RAW_DATA = data[\"arr_0\"]\n",
    "\n",
    "print(RAW_DATA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a904a158-5ad5-4f39-bb76-2e4a9c152b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 1001\n",
    "TEST_SIZE = 32\n",
    "TRAIN_SIZE = 200 - TEST_SIZE\n",
    "\n",
    "assert TRAIN_SIZE + TEST_SIZE <= RAW_DATA.shape[0]\n",
    "assert MAX_LEN <= RAW_DATA.shape[1]\n",
    "# PAD_VALUE = -1e10\n",
    "# is_pad = lambda x: np.isclose(x, PAD_VALUE)\n",
    "\n",
    "\n",
    "class DictDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dictionary):\n",
    "        self.dictionary = dictionary\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {key: values[index] for key, values in self.dictionary.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(next(iter(self.dictionary.values())))\n",
    "        \n",
    "\n",
    "def get_datasets(\n",
    "    batch_size,\n",
    "    data=RAW_DATA,\n",
    "    max_len=MAX_LEN,\n",
    "    train_size=TRAIN_SIZE,\n",
    "    test_size=TEST_SIZE,\n",
    "):\n",
    "    data = data[:, :max_len, :]\n",
    "    train_x = torch.FloatTensor(data[:train_size, :max_len, 0][..., None])\n",
    "    train_y = torch.FloatTensor(data[:train_size, :max_len, 1][..., None])\n",
    "    # train_pad = torch.BoolTensor(is_pad(data[:train_size, :max_len, 0]))\n",
    "    test_x = torch.FloatTensor(data[-test_size:, :max_len, 0][..., None])\n",
    "    test_y = torch.FloatTensor(data[-test_size:, :max_len, 1][..., None])\n",
    "    # test_pad = torch.BoolTensor(is_pad(data[-test_size:, :max_len, 0]))\n",
    "\n",
    "    train_ds = DictDataset({\"x\": train_x, \"y\": train_y})\n",
    "    test_ds = DictDataset({\"x\": test_x, \"y\": test_y})\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "284f2edf-d5b8-434a-99b7-308e30cde070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils.\n",
    "\n",
    "\n",
    "def create_learning_rate_scheduler(warmup_steps=1000, total_steps=10000):\n",
    "\n",
    "    def lr_lambda(step):\n",
    "        lr = 1.0\n",
    "        lr *= min(1.0, step / warmup_steps)\n",
    "        lr *= min(1.0, (total_steps - step) / (total_steps - warmup_steps))\n",
    "        return lr\n",
    "\n",
    "    return lr_lambda\n",
    "\n",
    "\n",
    "def compute_l2(predictions, targets, padding=None):\n",
    "    if predictions.ndim != targets.ndim:\n",
    "        raise ValueError(\n",
    "            f\"Incorrect shapes. Got shape {predictions.shape} predictions and {targets.shape} targets\"\n",
    "        )\n",
    "    padding = padding or torch.zeros(\n",
    "        predictions.shape[:-1], dtype=torch.bool, device=predictions.device\n",
    "    )\n",
    "\n",
    "    predictions = predictions * ~padding.unsqueeze(-1)\n",
    "    targets = targets * ~padding.unsqueeze(-1)\n",
    "    loss = ((predictions - targets) ** 2).sum(dim=-1)\n",
    "    return loss.mean()\n",
    "\n",
    "\n",
    "def compute_hinge(values):\n",
    "    assert values.dim() == 2, f\"{values.dim()} != 2\"\n",
    "    loss = torch.clamp(values, min=0)\n",
    "    return loss.mean()\n",
    "\n",
    "\n",
    "def compute_losses(\n",
    "    py,\n",
    "    pdy,\n",
    "    physics_aux,\n",
    "    y,\n",
    "    dy,\n",
    "    padding=None,\n",
    "    deltas_loss_weight=0.0,\n",
    "    physics_loss_weight=0.0,\n",
    "):\n",
    "    l = compute_l2(py, y)\n",
    "    ld = compute_l2(pdy, dy)\n",
    "    l2_loss = (1 - deltas_loss_weight) * l + deltas_loss_weight * ld\n",
    "    if physics_aux is not None:\n",
    "        physics_loss = compute_hinge(physics_aux)\n",
    "    else:\n",
    "        physics_loss = torch.zeros([])\n",
    "        assert physics_loss_weight == 0.0\n",
    "\n",
    "    loss = l2_loss + physics_loss_weight * physics_loss\n",
    "    return {\n",
    "        \"loss\": loss,\n",
    "        \"l2_loss\": l2_loss,\n",
    "        \"physics_loss\": physics_loss,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f411a019-2d0d-4a15-ba1d-f005040021b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_deltas(x):\n",
    "    dx = x[:, 1:, :] - x[:, :-1, :]\n",
    "    first_dx = torch.zeros((x.shape[0], 1, x.shape[2]), dtype=x.dtype, device=x.device)\n",
    "    dx = torch.cat([first_dx, dx], dim=1)\n",
    "    return dx\n",
    "\n",
    "\n",
    "class TransformerConfig:\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_size: int = 1,\n",
    "        max_len: int = MAX_LEN,\n",
    "        num_layers: int = 2,\n",
    "        hidden_dim: int = 16,\n",
    "        mlp_dim: int = 64,\n",
    "        num_heads: int = 4,\n",
    "        dropout_rate: float = 0.0,\n",
    "        attention_dropout_rate: float = 0.0,\n",
    "        deterministic: bool = False,\n",
    "        decode: bool = False,\n",
    "        causal_x: bool = True,\n",
    "        physics_decoder: bool = False,\n",
    "    ):\n",
    "        self.output_size = output_size\n",
    "        self.max_len = max_len\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.mlp_dim = mlp_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.attention_dropout_rate = attention_dropout_rate\n",
    "        self.deterministic = deterministic\n",
    "        self.decode = decode\n",
    "        self.causal_x = causal_x\n",
    "        self.physics_decoder = physics_decoder\n",
    "\n",
    "\n",
    "class AddPositionEmbs(nn.Module):\n",
    "    def __init__(self, config: TransformerConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.pos_embedding = nn.Parameter(\n",
    "            torch.randn(1, config.max_len, config.hidden_dim) * 0.02\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        assert (\n",
    "            inputs.ndim == 3\n",
    "        ), f\"Number of dimensions should be 3, but it is: {inputs.ndim}\"\n",
    "        return inputs + self.pos_embedding[:, : inputs.shape[1], :]\n",
    "\n",
    "\n",
    "class MlpBlock(nn.Module):\n",
    "    def __init__(self, config: TransformerConfig, out_dim: Optional[int] = None):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.out_dim = out_dim if out_dim is not None else config.hidden_dim\n",
    "        self.dense1 = nn.Linear(config.hidden_dim, config.mlp_dim)\n",
    "        self.dense2 = nn.Linear(config.mlp_dim, self.out_dim)\n",
    "        self.dropout = nn.Dropout(config.dropout_rate)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense2(x)\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class EncoderDecoder1DBlock(nn.Module):\n",
    "    def __init__(self, config: TransformerConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.ln1 = nn.LayerNorm(config.hidden_dim)\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            config.hidden_dim,\n",
    "            config.num_heads,\n",
    "            dropout=config.attention_dropout_rate,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(config.dropout_rate)\n",
    "        self.ln2 = nn.LayerNorm(config.hidden_dim)\n",
    "        self.mlp = MlpBlock(config)\n",
    "\n",
    "    def forward(self, inputs, decoder_mask=None):\n",
    "        x = self.ln1(inputs)\n",
    "        x, _ = self.attention(x, x, x, attn_mask=decoder_mask)\n",
    "        x = self.dropout(x)\n",
    "        x = x + inputs\n",
    "        z = self.ln2(x)\n",
    "        z = self.mlp(z)\n",
    "        return x + z\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, config: TransformerConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embed_x = nn.Linear(1, config.hidden_dim // 2)\n",
    "        self.embed_dx = nn.Linear(1, config.hidden_dim // 2)\n",
    "        self.pos_embed = AddPositionEmbs(config)\n",
    "        self.dropout = nn.Dropout(config.dropout_rate)\n",
    "        self.layers = nn.ModuleList(\n",
    "            [EncoderDecoder1DBlock(config) for _ in range(config.num_layers)]\n",
    "        )\n",
    "        self.ln = nn.LayerNorm(config.hidden_dim)\n",
    "        self.logits_x = nn.Linear(config.hidden_dim, config.output_size)\n",
    "        self.logits_dx = nn.Linear(config.hidden_dim, config.output_size)\n",
    "\n",
    "    def forward(self, inputs, decoder_mask=None):\n",
    "        x = inputs[\"x\"]\n",
    "        dx = build_deltas(x)\n",
    "\n",
    "        x = self.embed_x(x)\n",
    "        dx = self.embed_dx(dx)\n",
    "        x = torch.cat([x, dx], dim=-1)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.pos_embed(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, decoder_mask=decoder_mask)\n",
    "\n",
    "        x = self.ln(x)\n",
    "        logits_x = self.logits_x(x)\n",
    "        logits_dx = self.logits_dx(x)\n",
    "\n",
    "        return logits_x, logits_dx, None\n",
    "\n",
    "\n",
    "# TODO add physics transformer.\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, config: TransformerConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.decoder = Decoder(config)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        cfg = self.config\n",
    "        decoder_mask = None\n",
    "        if cfg.causal_x:\n",
    "            decoder_mask = nn.Transformer.generate_square_subsequent_mask(\n",
    "                inputs[\"x\"].shape[1]\n",
    "            ).to(inputs[\"x\"].device)\n",
    "\n",
    "        logits_x, logits_dx, aux = self.decoder(inputs, decoder_mask=decoder_mask)\n",
    "        return logits_x, logits_dx, aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5557f717-948a-44e2-b4de-d5ba20a7130d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0001,\ttrain loss 0.480,\ttrain l2 0.480,\ttrain aux 0.000,\teval loss 0.489,\teval l2 0.489,\teval aux 0.000,\tsteps/s 1576.7,\tlr 0.00002\n",
      "Step: 0500,\ttrain loss 0.093,\ttrain l2 0.093,\ttrain aux 0.000,\teval loss 0.012,\teval l2 0.012,\teval aux 0.000,\tsteps/s 42.5,\tlr 0.01000\n",
      "Step: 1000,\ttrain loss 0.008,\ttrain l2 0.008,\ttrain aux 0.000,\teval loss 0.006,\teval l2 0.006,\teval aux 0.000,\tsteps/s 42.4,\tlr 0.00889\n",
      "Step: 1500,\ttrain loss 0.004,\ttrain l2 0.004,\ttrain aux 0.000,\teval loss 0.004,\teval l2 0.004,\teval aux 0.000,\tsteps/s 42.7,\tlr 0.00778\n",
      "Step: 2000,\ttrain loss 0.002,\ttrain l2 0.002,\ttrain aux 0.000,\teval loss 0.005,\teval l2 0.005,\teval aux 0.000,\tsteps/s 42.4,\tlr 0.00667\n",
      "Step: 2500,\ttrain loss 0.002,\ttrain l2 0.002,\ttrain aux 0.000,\teval loss 0.003,\teval l2 0.003,\teval aux 0.000,\tsteps/s 42.7,\tlr 0.00556\n",
      "Step: 3000,\ttrain loss 0.002,\ttrain l2 0.002,\ttrain aux 0.000,\teval loss 0.003,\teval l2 0.003,\teval aux 0.000,\tsteps/s 42.5,\tlr 0.00444\n",
      "Step: 3500,\ttrain loss 0.001,\ttrain l2 0.001,\ttrain aux 0.000,\teval loss 0.003,\teval l2 0.003,\teval aux 0.000,\tsteps/s 42.5,\tlr 0.00333\n",
      "Step: 4000,\ttrain loss 0.001,\ttrain l2 0.001,\ttrain aux 0.000,\teval loss 0.002,\teval l2 0.002,\teval aux 0.000,\tsteps/s 42.7,\tlr 0.00222\n",
      "Step: 4500,\ttrain loss 0.001,\ttrain l2 0.001,\ttrain aux 0.000,\teval loss 0.002,\teval l2 0.002,\teval aux 0.000,\tsteps/s 42.2,\tlr 0.00111\n",
      "Training completed after 5000 steps.\n"
     ]
    }
   ],
   "source": [
    "hparams = {\n",
    "    \"random_seed\": 0,\n",
    "    \"model_dir\": \"/tmp/test\",\n",
    "    \"physics_decoder\": False,\n",
    "    \"max_len\": MAX_LEN,\n",
    "    \"num_layers\": 4,\n",
    "    \"hidden_dim\": 16,\n",
    "    \"mlp_dim\": 64,\n",
    "    \"num_heads\": 2,\n",
    "    \"dropout_rate\": 0.0,\n",
    "    \"attention_dropout_rate\": 0.0,\n",
    "    \"deltas_loss_weight\": 0.0,\n",
    "    \"physics_loss_weight\": 0.0,\n",
    "    \"causal_x\": True,  # TODO add\n",
    "    \"batch_size\": 16,\n",
    "    \"learning_rate\": 1e-2,\n",
    "    \"weight_decay\": 0.0,\n",
    "    \"warmup_steps\": 500,\n",
    "    \"total_steps\": 5000,\n",
    "    \"eval_freq\": 500,\n",
    "}\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.manual_seed(hparams[\"random_seed\"])\n",
    "\n",
    "train_loader, eval_loader = get_datasets(batch_size=hparams[\"batch_size\"])\n",
    "\n",
    "config = TransformerConfig(\n",
    "    max_len=hparams[\"max_len\"],\n",
    "    num_layers=hparams[\"num_layers\"],\n",
    "    hidden_dim=hparams[\"hidden_dim\"],\n",
    "    mlp_dim=hparams[\"mlp_dim\"],\n",
    "    num_heads=hparams[\"num_heads\"],\n",
    "    dropout_rate=hparams[\"dropout_rate\"],\n",
    "    attention_dropout_rate=hparams[\"attention_dropout_rate\"],\n",
    "    causal_x=hparams[\"causal_x\"],\n",
    "    physics_decoder=hparams[\"physics_decoder\"],\n",
    ")\n",
    "model = Transformer(config).to(device)\n",
    "model.train()\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=hparams[\"learning_rate\"],\n",
    "    weight_decay=hparams[\"weight_decay\"],\n",
    ")\n",
    "scheduler = optim.lr_scheduler.LambdaLR(\n",
    "    optimizer,\n",
    "    create_learning_rate_scheduler(\n",
    "        warmup_steps=hparams[\"warmup_steps\"], total_steps=hparams[\"total_steps\"]\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def forward(model, inputs, deltas_loss_weight, physics_loss_weight):\n",
    "    optimizer.zero_grad()\n",
    "    py, pdy, physics_aux = model(inputs)\n",
    "    y = inputs[\"y\"]\n",
    "    dy = build_deltas(y)\n",
    "    return compute_losses(\n",
    "        py=py,\n",
    "        pdy=pdy,\n",
    "        physics_aux=physics_aux,\n",
    "        y=y,\n",
    "        dy=dy,\n",
    "        deltas_loss_weight=deltas_loss_weight,\n",
    "        physics_loss_weight=physics_loss_weight,\n",
    "    )\n",
    "\n",
    "\n",
    "metrics_all = []\n",
    "total_steps = 0\n",
    "tick = time.time()\n",
    "\n",
    "while total_steps < hparams[\"total_steps\"]:\n",
    "    for batch in train_loader:\n",
    "\n",
    "        if total_steps == 1 or (\n",
    "            total_steps % hparams[\"eval_freq\"] == 0 and total_steps > 0\n",
    "        ):\n",
    "            summary = {k: np.mean([m[k] for m in metrics_all]) for k in metrics_all[0]}\n",
    "            summary[\"learning_rate\"] = scheduler.get_last_lr()[0]\n",
    "            metrics_all = []\n",
    "\n",
    "            tock = time.time()\n",
    "            steps_per_sec = hparams[\"eval_freq\"] / (tock - tick)\n",
    "            tick = tock\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            eval_metrics = []\n",
    "            with torch.no_grad():\n",
    "                for eval_batch in eval_loader:\n",
    "                    eval_batch = {k: v.to(device) for k, v in eval_batch.items()}\n",
    "                    metrics = forward(\n",
    "                        model,\n",
    "                        eval_batch,\n",
    "                        hparams[\"deltas_loss_weight\"],\n",
    "                        hparams[\"physics_loss_weight\"],\n",
    "                    )\n",
    "                    eval_metrics.append(\n",
    "                        {\n",
    "                            k: v.detach().item() if v is not None else None\n",
    "                            for k, v in metrics.items()\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "            eval_summary = {\n",
    "                k: np.mean([m[k] for m in eval_metrics]) for k in eval_metrics[0]\n",
    "            }\n",
    "\n",
    "            print(\n",
    "                f\"Step: {total_steps:04d},\\ttrain loss {summary['loss']:.3f},\\t\"\n",
    "                f\"train l2 {summary['l2_loss']:.3f},\\ttrain aux {summary['physics_loss']:.3f},\\t\"\n",
    "                f\"eval loss {eval_summary['loss']:.3f},\\teval l2 {eval_summary['l2_loss']:.3f},\\t\"\n",
    "                f\"eval aux {eval_summary['physics_loss']:.3f},\\tsteps/s {steps_per_sec:.1f},\\t\"\n",
    "                f\"lr {summary['learning_rate']:.5f}\"\n",
    "            )\n",
    "\n",
    "            model.train()\n",
    "\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        optimizer.zero_grad()\n",
    "        metrics = forward(\n",
    "            model,\n",
    "            batch,\n",
    "            hparams[\"deltas_loss_weight\"],\n",
    "            hparams[\"physics_loss_weight\"],\n",
    "        )\n",
    "        metrics[\"loss\"].backward()\n",
    "        optimizer.step()\n",
    "        metrics_all.append(\n",
    "            {\n",
    "                k: v.detach().item() if v is not None else None\n",
    "                for k, v in metrics.items()\n",
    "            }\n",
    "        )\n",
    "        scheduler.step()\n",
    "        total_steps += 1\n",
    "\n",
    "        if total_steps >= hparams[\"total_steps\"]:\n",
    "            break\n",
    "\n",
    "print(f\"Training completed after {total_steps} steps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b10bd0-7919-42c9-9657-e4b807c204d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
